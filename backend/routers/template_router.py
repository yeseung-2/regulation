from fastapi import APIRouter
from pydantic import BaseModel
from services.vector_loader import load_vectorstore
from pathlib import Path
from bs4 import BeautifulSoup
from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
import re
from dotenv import load_dotenv
from key import key
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from difflib import SequenceMatcher
from fastapi.responses import FileResponse
from weasyprint import HTML
from jinja2 import Environment, FileSystemLoader
from datetime import datetime
from pathlib import Path
import uuid
from typing import List, Optional
import requests
from .models.draft_model import Draft
from pymongo import MongoClient
import os


load_dotenv()

router = APIRouter()
print("âœ… template_router loaded")

client = MongoClient(os.getenv("MONGO_URI"))
db = client["esg_templates_db"]
drafts = db["drafts"]

def call_hyperclova_llm(system_msg: SystemMessage, human_msg: HumanMessage) -> str:
    prompt = f"{system_msg.content.strip()}\n\n{human_msg.content.strip()}"

    headers = {
        "Authorization": f"Bearer {key['HUGGINGFACE_API_TOKEN']}",
        "Content-Type": "application/json"
    }

    url = "https://api-inference.huggingface.co/models/naver-hyperclovax/HyperCLOVAX-SEED-Text-Base-3B"
    payload = {
        "inputs": prompt
    }

    try:
        res = requests.post(url, headers=headers, json=payload, timeout=60)
        res.raise_for_status()
        return res.json()[0]["generated_text"]
    except Exception as e:
        print(f"âŒ Hugging Face LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return "âš ï¸ ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
class HistoryItem(BaseModel):
    date: str
    description: str

class TemplateRequest(BaseModel):
    company: str
    topic: str
    department: Optional[str] = ""
    history: Optional[List[HistoryItem]] = []

class HtmlToPdfRequest(BaseModel):
    topic: str
    company: str
    department: str
    html: str
    history: List[HistoryItem]

@router.post("/generate")
def generate_template(req: TemplateRequest):
    from difflib import SequenceMatcher

    vectorstore = load_vectorstore("esg_templates")

    # âœ… ì²­í¬ í•„í„°ë§ ë° ì •ë ¬
    all_docs = list(vectorstore.docstore._dict.values())
    filtered = [d for d in all_docs if d.metadata.get("title") == req.topic]
    if not filtered:
        return {"template": "âŒ í•´ë‹¹ ì£¼ì œì— ëŒ€í•œ ê·œì •ì•ˆì´ ì—†ìŠµë‹ˆë‹¤."}
    filtered = sorted(filtered, key=lambda d: d.metadata.get("chunk_id", ""))

    # âœ… í‘œ ë¡œë”©
    table_paths, table_htmls, table_texts, seen = [], [], [], set()
    max_table_count = len(table_htmls)
    print(f"ë§¥ìŠ¤í…Œì´ë¸”:{max_table_count}")
    for doc in filtered:
        t_raw = doc.metadata.get("tables", [])
        t_list = eval(t_raw) if isinstance(t_raw, str) else t_raw
        for path in t_list:
            if path not in seen:
                seen.add(path)
                table_paths.append(path)
                try:
                    soup = BeautifulSoup(Path(path).read_text(encoding="utf-8"), "html.parser")
                    h3 = soup.find("h3")
                    table = soup.find("table")
                    if table:
                        combined = str(h3) + "\n" if h3 else ""
                        combined += str(table)
                        table_htmls.append(combined)
                        table_texts.append(soup.get_text(separator="\n", strip=True))
                except Exception as e:
                    print(f"âŒ í‘œ ì½ê¸° ì‹¤íŒ¨: {path} â†’ {e}")

    # âœ… LLM ì¤€ë¹„ (GPTëŠ” ë§ˆì»¤/í‘œ ì¶œë ¥ ê¸ˆì§€)
    llm = ChatOpenAI(
        model="gpt-4o",
        temperature=0.2,
        max_tokens=2048,
        openai_api_key=key["OPENAI_API_KEY"]
    )
    system_msg = SystemMessage(content=f"""\
ë„ˆëŠ” ESG ê·œì •ì•ˆ ë¬¸ì„œë¥¼ ì •ëˆí•˜ëŠ” ë„ìš°ë¯¸ì•¼.

ğŸ“Œ ë°˜ë“œì‹œ ì•„ë˜ ì§€ì¹¨ì„ ë”°ë¼ì•¼ í•´:

1. ë¬¸ì„œì˜ ì œëª©, ì¡°ë¬¸ êµ¬ì¡°, í•­ëª© ìˆœì„œë¥¼ ë°”ê¾¸ê±°ë‚˜ ìš”ì•½í•˜ì§€ ë§ˆ.
2. ê° í‘œê°€ ë“¤ì–´ê°ˆ ìœ„ì¹˜ì— ì •í™•íˆ `[[TABLE_N]]` ë§ˆì»¤ë¥¼ í¬í•¨ì‹œì¼œ. ì ˆëŒ€ ëˆ„ë½í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ì§€ ë§ˆ.
3. ë‹¨, ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í‘œ ë§ˆì»¤ëŠ” `[[TABLE_1]]`ë¶€í„° `[[TABLE_{max_table_count}]]`ê°œ ê¹Œì§€ë§Œì´ì•¼. ê·¸ ì´ìƒì€ ì ˆëŒ€ ë§Œë“¤ì§€ ë§ˆ.
4. í‘œ HTML(<table>, <tr>, <td> ë“±)ì€ ì ˆëŒ€ ë³¸ë¬¸ì— ì¶œë ¥í•˜ì§€ ë§ˆ. ë§ˆì»¤ë§Œ ë„£ì–´.
5. ì²­í¬ê°€ ì¡°ë¬¸ì´ë‚˜ ë¬¸ë‹¨ ì¤‘ê°„ì—ì„œ ëŠê²¨ì„œ ì–´ìƒ‰í•œ ê²½ìš°, ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ ë¬¸ì¥ì„ ì •ë¦¬í•´ì¤˜.
6. ë¬¸ì¥ ìˆœì„œë‚˜ ì˜ë¯¸ëŠ” ë°”ê¾¸ì§€ ë§ê³ , ëŠê¹€ssssssssì´ ëŠê»´ì§€ëŠ” ë¶€ë¶„ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ë³´ì™„í•´.
7. ì¡°ë¬¸ì€ 1ì¡°, 2ì¡°, 3ì¡° ... ìˆ«ìê°€ ëŠê¹€ ì—†ì´ ì´ì–´ì§€ë„ë¡ ì •ëˆí•´.
8. ë¬¸ë‹¨ ê°„ ì¤„ë°”ê¿ˆì´ë‚˜ ë“¤ì—¬ì“°ê¸°ëŠ” ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬í•´ë„ ì¢‹ì•„.
""")

    # âœ… ì²­í¬ ê·¸ë£¹ ë‚˜ëˆ„ê¸°
    CHUNKS_PER_REQUEST = 10
    chunk_groups = [
        filtered[i:i + CHUNKS_PER_REQUEST]
        for i in range(0, len(filtered), CHUNKS_PER_REQUEST)
    ]
    print(f"ğŸ“š {len(chunk_groups)}ê°œ ê·¸ë£¹ìœ¼ë¡œ ë¶„í• ë¨ (ê·¸ë£¹ë‹¹ ìµœëŒ€ {CHUNKS_PER_REQUEST}ê°œ)")

    # âœ… ê·¸ë£¹ë³„ GPT í˜¸ì¶œ
    results = []
    for group_idx, group in enumerate(chunk_groups):
        chunk_ids = [d.metadata.get("chunk_id", "?") for d in group]
        print(f"ğŸ”¹ ê·¸ë£¹ {group_idx+1}: chunk_ids = {chunk_ids}")

        group_text = "\n\n".join([d.page_content for d in group])
        print(f"ğŸ“„ ê·¸ë£¹ {group_idx+1} í…ìŠ¤íŠ¸ ì‹œì‘:\n{group_text[:300]}...\n")

        group_text = (
            group_text.replace("[ê¸°ì—…ëª…]", req.company)
                      .replace("{íšŒì‚¬ëª…}", req.company)
                      .replace("ê¸°ì—…ëª… ì€", f"{req.company}ì€")
                      .replace("ãˆœâ–³â–³â–³ì‚¬", req.company)
                      .replace("ê¸°ì—…ëª…", req.company)
        )
        group_text = re.sub(r"\n{2,}", "\n\n", group_text)

        human_msg = HumanMessage(content=f"""
ğŸ“„ ê·œì •ì•ˆ ì›ë¬¸:
{group_text}
""")
        try:
            response = llm.invoke([system_msg, human_msg])
            print(f"ğŸ“¤ ê·¸ë£¹ {group_idx+1} ì‘ë‹µ ê¸¸ì´: {len(response.content)}")
            results.append(response.content)
        except Exception as e:
            print(f"âŒ GPT ê·¸ë£¹ {group_idx+1} í˜¸ì¶œ ì‹¤íŒ¨:", e)
            results.append("âš ï¸ GPT ì‘ë‹µ ì‹¤íŒ¨ (ì¼ë¶€)")

    # âœ… GPTê°€ ì‹¤ìˆ˜ë¡œ tableì„ ë„£ì—ˆì„ ê²½ìš° ì œê±°
    cleaned_results = []
    for r in results:
        for html in table_htmls:
            r = r.replace(html, "")
        cleaned_results.append(r)

    output_text = "\n\n".join(cleaned_results)

    # âœ… ë§ˆì»¤ ì‚½ì… í•¨ìˆ˜
    def insert_marker_safely(text, marker, table_text):
        if marker in text:
            print(f"âš ï¸ ë§ˆì»¤ {marker} ì´ë¯¸ ì¡´ì¬ â†’ ì‚½ì… ìƒëµ")
            return text

        paragraphs = text.split("\n\n")
        best_score, best_idx = 0, -1
        for i, para in enumerate(paragraphs):
            score = SequenceMatcher(None, para, table_text).ratio()
            if score > best_score:
                best_score, best_idx = score, i

        if best_score > 0.5:
            print(f"âœ… ìœ ì‚¬ë„ {best_score:.2f} â†’ ë§ˆì»¤ {marker} ì‚½ì… (ë¬¸ë‹¨ {best_idx})")
            paragraphs[best_idx] += f"\n\n{marker}"
        else:
            print(f"âš ï¸ ìœ ì‚¬ ë¬¸ë‹¨ ì—†ìŒ â†’ ë§ˆì»¤ {marker} ë³¸ë¬¸ ëì— ì‚½ì…")
            paragraphs.append(marker)

        return "\n\n".join(paragraphs)

    # âœ… ë§ˆì»¤ ì‚½ì… (ë°±ì—”ë“œ ì „ë‹´)
    for i, table_text in enumerate(table_texts):
        marker = f"[[TABLE_{i+1}]]"
        if marker not in output_text:
            print(f"âŒ ë§ˆì»¤ {marker} ì—†ìŒ â†’ ì‚½ì… ì‹œë„")
            output_text = insert_marker_safely(output_text, marker, table_text)
        else:
            print(f"âœ… ë§ˆì»¤ {marker} ì´ë¯¸ ì¡´ì¬ â†’ ì‚½ì… ìƒëµ")

    # âœ… ë§ˆì»¤ë¥¼ ì‹¤ì œ tableë¡œ ì¹˜í™˜
    for i, html in enumerate(table_htmls):
        marker = f"[[TABLE_{i+1}]]"
        if marker in output_text:
            output_text = output_text.replace(marker, html)
            print(f"âœ… ë§ˆì»¤ {marker} â†’ <table> ì‚½ì… ì™„ë£Œ")
        else:
            print(f"âš ï¸ ë§ˆì»¤ {marker} ì—†ìŒ â†’ <table> ì‚½ì… ìƒëµ")

    return {
        "template": output_text,
        "topic": req.topic,
        "company": req.company,
        "department": req.department,
        "history": req.history,
        "chunk_count": len(filtered),
        "table_html": "",
        "table_paths": table_paths,
    }

@router.post("/generate-pdf")
def generate_template_pdf(req: TemplateRequest):  # ì´ë¯¸ ì¡´ì¬í•  ê²½ìš° ìƒëµ ê°€ëŠ¥
    result = generate_template(req)
    html_content = result["template"]

    # í…œí”Œë¦¿ ë Œë”ë§
    env = Environment(loader=FileSystemLoader("templates"))
    template = env.get_template("esg_template.html")
    rendered_html = template.render(
        topic=req.topic,
        company=req.company,
        department=req.department,
        date=datetime.now().strftime("%Y.%m.%d"),
        content=req.html,
        history=req.history
    )

    # PDF ì €ì¥ ê²½ë¡œ ì„¤ì •
    output_dir = Path("static/pdf")
    output_dir.mkdir(parents=True, exist_ok=True)
    file_name = f"{uuid.uuid4()}.pdf"
    pdf_path = output_dir / file_name

    # PDF ìƒì„±
    HTML(string=rendered_html).write_pdf(str(pdf_path))

    # ì‚¬ìš©ìì—ê²Œ íŒŒì¼ ë‹¤ìš´ë¡œë“œë¡œ ì‘ë‹µ
    return FileResponse(
        path=str(pdf_path),
        filename=f"{req.company}_{req.topic}.pdf",
        media_type="application/pdf"
    )

@router.post("/download-pdf-from-html")
def download_pdf_from_html(req: HtmlToPdfRequest):
    env = Environment(loader=FileSystemLoader("templates"))
    template = env.get_template("esg_template.html")
    rendered_html = template.render(
        topic=req.topic,
        company=req.company,
        department=req.department,  
        history=req.history,       
        content=req.html
    )


    output_dir = Path("static/pdf")
    output_dir.mkdir(parents=True, exist_ok=True)
    file_name = f"{uuid.uuid4()}.pdf"
    pdf_path = output_dir / file_name
    HTML(string=rendered_html).write_pdf(str(pdf_path))

    return FileResponse(
        path=str(pdf_path),
        filename=f"{req.company}_{req.topic}.pdf",
        media_type="application/pdf"
    )

@router.get("/list-drafts")
def list_drafts(user_id: str):
    items = drafts.find({"user_id": user_id}, {"_id": 0, "company": 1, "topic": 1, "timestamp": 1, "department": 1})
    return list(items)

@router.post("/save-draft")
def save_draft(draft: Draft):
    draft_dict = draft.dict()
    draft_dict["timestamp"] = datetime.utcnow()
    if "is_final" not in draft_dict:
        draft_dict["is_final"] = False

    drafts.update_one(
        {"user_id": draft.user_id, "topic": draft.topic},
        {"$set": draft_dict},
        upsert=True
    )
    return {"message": "âœ… ì´ˆì•ˆ ì €ì¥ ì™„ë£Œ"}

@router.get("/load-draft")
def load_draft(user_id: str, topic: str):
    print(f"ğŸ“¥ load-draft ìš”ì²­: user_id={user_id}, topic={topic}")
    draft = drafts.find_one({"user_id": user_id, "topic": topic}, {"_id": 0})
    if draft:
        return draft
    return {"message": "âŒ í•´ë‹¹ ì´ˆì•ˆ ì—†ìŒ"}

@router.delete("/delete-draft")
def delete_draft(user_id: str, topic: str):
    result = drafts.delete_one({"user_id": user_id, "topic": topic})
    if result.deleted_count == 1:
        return {"message": "âœ… ì´ˆì•ˆ ì‚­ì œ ì™„ë£Œ"}
    return {"message": "âŒ í•´ë‹¹ ì´ˆì•ˆ ì—†ìŒ"}