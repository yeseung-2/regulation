from fastapi import APIRouter, Body, Request
from pydantic import BaseModel
from services.vector_loader import load_vectorstore
from bs4 import BeautifulSoup
from pathlib import Path
from typing import List, Optional
import json
from key import key
import re
from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from services.draft_store import save_draft, load_draft
from fastapi import HTTPException
from pydantic import BaseModel
from bs4 import BeautifulSoup
import difflib
from difflib import SequenceMatcher
from typing import Dict, Any
from services.draft_store import save_input_data, load_input_data
from services.db import draft_collection, input_collection 


router = APIRouter()
print("âœ… environment_router (fetch-only) loaded")

TABLE_DIR = Path(__file__).resolve().parent.parent / "extracted/2025_Sustainable_Management_Manual_split/tables"

class DeleteDraftRequest(BaseModel):
    topic: str
    company: str

class HistoryItem(BaseModel):
    date: str
    description: str

class FetchDataRequest(BaseModel):
    topic: str
    company: Optional[str] = ""
    department: Optional[str] = ""
    history: Optional[str] = ""
# âœ… ì‘ì„± ë‚´ìš© ë¸”ë¡ ì¶”ì¶œ í•¨ìˆ˜ (ì¶”ê°€)
def extract_ì‘ì„±ë‚´ìš©(chunks: List[str]) -> str:
    lines = "\n".join(chunks).splitlines()
    capture = False
    result = []

    for line in lines:
        stripped = line.strip()
        if "ì‘ì„± ë‚´ìš©" in stripped:
            capture = True
        elif stripped.startswith("â–¶") or stripped.startswith("KBZ-"):
            if capture:
                break
        if capture:
            result.append(stripped)

    return "\n".join(result).strip()

# ì…ë ¥ê°’ ì„ì‹œì €ì¥ ëª¨ë¸
class SaveInputsRequest(BaseModel):
    topic: str
    company: str
    inputs: dict
    table: dict
    improvement: Optional[str] = ""



@router.post("/save-inputs")
def save_inputs(req: SaveInputsRequest):
    data = {
        "inputs": req.inputs,
        "table": req.table,
        "improvement": req.improvement,
    }
    save_input_data(f"{req.topic}__input", req.company, data)
    return {"message": "âœ… ì…ë ¥ê°’ ì„ì‹œ ì €ì¥ë¨"}

@router.get("/load-inputs")
def load_inputs(topic: str, company: str):
    data = load_input_data(f"{topic}__input", company)
    return {"inputs": data or {}}

@router.post("/fetch-data")
def fetch_data(req: FetchDataRequest):
    from services.vector_loader import load_vectorstore
    from bs4 import BeautifulSoup
    import json

    # âœ… 1. ë²¡í„°ìŠ¤í† ì–´ ë¡œë”©
    vectorstore = load_vectorstore("esg_Manual")
    all_docs = list(vectorstore.docstore._dict.values())

    # âœ… 2. topicìœ¼ë¡œ í•„í„°ë§
    filtered = [
        doc for doc in all_docs
        if req.topic in (doc.metadata.get("title") or "")
    ]
    filtered = sorted(filtered, key=lambda d: d.metadata.get("chunk_id", ""))

    # âœ… 3. ê´€ë ¨ í˜ì´ì§€ ì¶”ì¶œ
    pages = set()
    for doc in filtered:
        raw_pages = doc.metadata.get("pages", [])
        if isinstance(raw_pages, list):
            pages.update(raw_pages)
        elif isinstance(raw_pages, int):
            pages.add(raw_pages)
        elif isinstance(raw_pages, str):
            try:
                parsed = json.loads(raw_pages) if raw_pages.startswith("[") else eval(raw_pages)
                if isinstance(parsed, list):
                    pages.update(parsed)
                elif isinstance(parsed, int):
                    pages.add(parsed)
            except Exception as e:
                print(f"âŒ pages íŒŒì‹± ì‹¤íŒ¨: {raw_pages} â†’ {e}")

    # âœ… 4. í‘œ ë¡œë”© (ì—¬ëŸ¬ ê°œ ëŒ€ì‘)
    table_htmls, table_texts, table_paths = [], [], []
    for page in sorted(pages):
        for path in TABLE_DIR.glob(f"page{page}_table*.html"):
            try:
                soup = BeautifulSoup(path.read_text(encoding="utf-8"), "html.parser")
                table = soup.find("table")
                if table:
                    table_htmls.append(str(table))
                    table_texts.append(soup.get_text(separator="\n", strip=True))
                    table_paths.append(str(path))
            except Exception as e:
                print(f"âŒ í‘œ íŒŒì‹± ì‹¤íŒ¨: {path} â†’ {e}")

    print("ğŸ“„ ì¶”ì¶œëœ í˜ì´ì§€:", sorted(pages))
    print("ğŸ“Š ë¡œë”©ëœ í‘œ ê°œìˆ˜:", len(table_htmls))

    # âœ… 5. ìµœì¢… ì‘ë‹µ ë°˜í™˜
    return {
        "topic": req.topic,
        "company": req.company,
        "department": req.department,
        "history": req.history,
        "chunk_count": len(filtered),
        "chunks": [doc.page_content for doc in filtered],
        "table_htmls": table_htmls,        # âœ… ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜
        "table_paths": table_paths,
        "table_texts": table_texts,
        "pages": sorted(pages)
    }



from langchain_community.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

class InferDataRequest(BaseModel):
    topic: str
    chunks: List[str]
    table_texts: List[str]

from typing import List, Dict, Any
import re

def parse_markdown_to_fields(markdown: str) -> List[Dict[str, Any]]:
    rows = []
    lines = markdown.strip().splitlines()
    current_field = {}

    for line in lines:
        line = line.strip()

        # âœ… 1. í•­ëª©ëª… ê°ì§€ (ë³„í‘œ ìœ ë¬´ ëª¨ë‘ ì²˜ë¦¬)
        match_item = re.match(r"^\d+\.\s+(?:\*\*)?(.+?)(?:\*\*)?$", line)
        if match_item:
            if current_field and "í•­ëª©" in current_field:
                rows.append(current_field)
            current_field = {"í•­ëª©": match_item.group(1).strip()}
            continue

        # âœ… 2. ë‹¨ìœ„ ê°ì§€
        if "**ë‹¨ìœ„**" in line:
            match = re.search(r"\*\*ë‹¨ìœ„\*\*:\s*(.+)", line)
            if match:
                current_field["ë‹¨ìœ„"] = match.group(1).strip()

        # âœ… 3. ì—°ë„ ê°ì§€
        elif "**ì—°ë„ë³„ ë°ì´í„°**" in line:
            match = re.search(r"\*\*ì—°ë„ë³„ ë°ì´í„°\*\*:\s*(.+)", line)
            if match:
                current_field["ì—°ë„"] = match.group(1).strip()

        # âœ… 4. ì„¤ëª… ê°ì§€
        elif "**ì„¤ëª…**" in line:
            match = re.search(r"\*\*ì„¤ëª…\*\*:\s*(.+)", line)
            if match:
                current_field["ì„¤ëª…"] = match.group(1).strip()

    # âœ… ë§ˆì§€ë§‰ í•­ëª© ëˆ„ë½ ë°©ì§€
    if current_field and "í•­ëª©" in current_field:
        rows.append(current_field)

    return rows


def clean_and_split_fieldnames(text: str) -> List[str]:
    # ì¤„ë°”ê¿ˆ ì œê±°, ê´„í˜¸ ë‚´ìš© ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = text.replace("\\n", " ").replace("\n", " ")
    text = re.sub(r"\(.*?\)", "", text)
    text = re.sub(r"[^\w\sã„±-ã…ê°€-í£a-zA-Z0-9]", "", text)
    text = re.sub(r"\s+", " ", text).strip()

    # ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„ë¡œ ë¶„í•  (ì˜ˆ: 4~6ì ì´ìƒ í•œê¸€ ë¬¶ìŒ)
    candidates = re.findall(r"[ê°€-í£]{3,10}(?:\s[ê°€-í£]{2,10})*", text)

    # í•„í„°ë§: ë„ˆë¬´ ì§§ì€ ê±´ ì œê±°
    return [c.strip() for c in candidates if len(c.strip()) >= 4]


def extract_table_fieldnames(table_texts: List[str]) -> List[str]:
    """HTML + í…ìŠ¤íŠ¸ ê¸°ë°˜ í‘œì—ì„œ í•­ëª©ëª… ì¶”ì¶œ (ì¤„ë°”ê¿ˆ, ê´„í˜¸ ë“± ì œê±° í¬í•¨)"""
    def clean_fieldname(text: str) -> str:
        # ì¤„ë°”ê¿ˆ ì œê±° í›„ ê´„í˜¸ ë‚´ìš©, íŠ¹ìˆ˜ë¬¸ì ì œê±°
        text = text.replace("\n", " ")  # ì¤„ë°”ê¿ˆ ê³µë°± ì²˜ë¦¬
        text = re.sub(r"\(.*?\)", "", text)  # ê´„í˜¸ ì•ˆ ì œê±°
        text = re.sub(r"[^\w\sã„±-ã…ê°€-í£a-zA-Z0-9]", "", text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        text = re.sub(r"\s+", " ", text).strip()  # ì¤‘ë³µ ê³µë°± ì •ë¦¬
        return text

    fieldnames = set()

    for html_or_text in table_texts:
        # 1ï¸âƒ£ HTML ê¸°ë°˜ ì¶”ì¶œ
        try:
            soup = BeautifulSoup(html_or_text, "html.parser")
            table = soup.find("table")
            if table:
                thead = table.find("thead")
                if thead:
                    header_row = thead.find("tr")
                    if header_row:
                        for cell in header_row.find_all(["th", "td"]):
                            text = clean_fieldname(cell.get_text(strip=True))
                            if text and len(text) <= 50:
                                fieldnames.add(text)
                else:
                    tbody = table.find("tbody")
                    if tbody:
                        for row in tbody.find_all("tr"):
                            cells = row.find_all(["td", "th"])
                            if cells:
                                first_col = clean_fieldname(cells[0].get_text(strip=True))
                                if first_col and len(first_col) <= 50:
                                    fieldnames.add(first_col)
                continue  # HTML ì¶”ì¶œ ì„±ê³µ ì‹œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ìƒëµ
        except:
            pass

        # 2ï¸âƒ£ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì¶œ (ì¤„ í•˜ë‚˜ì— ì—¬ëŸ¬ í•­ëª©ì´ ë¶™ì€ ê²½ìš° ë¶„ë¦¬ ì²˜ë¦¬)
        lines = html_or_text.splitlines()
        for line in lines:
            line = line.strip()
            if not line or len(line) < 4:
                continue
            if line.startswith("êµ¬ë¶„") or line.startswith("ë‹¨ìœ„"):
                continue
            if any(unit in line for unit in ["í†¤", "TJ", "%", "tCO2eq", "ë°±ë§Œì›"]) and any(char.isdigit() for char in line):
                continue
            if re.search(r"\d{4}", line):  # ì—°ë„ í¬í•¨ ì¤„ ì œì™¸
                continue

            # âœ… ì˜ë¯¸ ìˆëŠ” í•­ëª© ë©ì–´ë¦¬ë“¤ì„ ë¶„ë¦¬í•´ ì¶”ì¶œ
            fieldname_candidates = clean_and_split_fieldnames(line)
            for f in fieldname_candidates:
                if len(f) >= 3:
                    fieldnames.add(f)


    return sorted(fieldnames)

def is_redundant(llm_field: str, table_fields: List[str], threshold=0.8) -> bool:
    llm_norm = normalize(llm_field)

    for table_field in table_fields:
        table_norm = normalize(table_field)

        # 1. ê¸°ì¡´ ìœ ì‚¬ë„ ê¸°ì¤€
        ratio = difflib.SequenceMatcher(None, llm_norm, table_norm).ratio()
        if ratio >= threshold:
            return True

        # âœ… 2. í¬í•¨ ê´€ê³„ ê¸°ì¤€ (í•œìª½ì´ ë‹¤ë¥¸ ìª½ì— í¬í•¨ë˜ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼)
        if llm_norm in table_norm or table_norm in llm_norm:
            return True

    return False


def normalize(text: str) -> str:
    return re.sub(r"[\s()%/+\-.,]", "", text).lower()

def is_similar(a: str, b: str, threshold=0.8) -> bool:
    return SequenceMatcher(None, normalize(a), normalize(b)).ratio() >= threshold

def remove_duplicate_fields(required_fields, table_fieldnames):
    return [
        field for field in required_fields
        if all(not is_similar(field["í•­ëª©"], tf) for tf in table_fieldnames)
    ]


@router.post("/infer-required-data")
def infer_required_data(req: InferDataRequest):
    llm = ChatOpenAI(
        model="gpt-4o",
        temperature=0.3,
        max_tokens=1024,
        openai_api_key=key["OPENAI_API_KEY"]
    )

    # ğŸ§  ì‹œìŠ¤í…œ ì§€ì¹¨
    system = SystemMessage(content="""
    ë„ˆëŠ” ESG ë³´ê³ ì„œ ì‘ì„± ì§€ì› ë„ìš°ë¯¸ì•¼.

    ì‚¬ìš©ìê°€ ì œê³µí•œ ì§€í‘œ ì„¤ëª…(ì²­í¬), ì‘ì„± ê°€ì´ë“œ, í‘œ ì˜ˆì‹œë¥¼ ë°”íƒ•ìœ¼ë¡œ,
    **ì´ ì§€í‘œë¥¼ ì‘ì„±í•˜ê¸° ìœ„í•´ ë°˜ë“œì‹œ ì…ë ¥ë°›ì•„ì•¼ í•  ë°ì´í„°ë¥¼** ì •ë¦¬í•´ì¤˜.

    ğŸ“Œ íŠ¹íˆ ì£¼ì˜í•  ì :
    - ë°˜ë“œì‹œ **'ì‘ì„± ë‚´ìš©' í•­ëª©**ì„ ìš°ì„ ì ìœ¼ë¡œ ë¶„ì„í•´ì„œ, í•´ë‹¹ ë‚´ìš©ì„ ë³´ê³ í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì…ë ¥ í•­ëª©ì„ ë¹ ì§ì—†ì´ ì¶”ì¶œí•´ì¤˜.
    - ì‘ì„± ë‚´ìš©ì— ìˆëŠ” í•­ëª©ì€ í‘œì— ì—†ì–´ë„ ë°˜ë“œì‹œ í¬í•¨í•´.
    - **í‘œëŠ” ì°¸ê³  ìë£Œì¼ ë¿ì´ì•¼. ì‘ì„± ë‚´ìš©ì´ ì¤‘ìš”í•´.**

    ğŸ“› ë˜í•œ, í‘œì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í•­ëª©ëª…ê³¼ 90% ì´ìƒ ìœ ì‚¬í•œ í•­ëª©ì€ ì¶”ì²œí•˜ì§€ ë§ˆ.
    - ì˜ˆ: í‘œì— â€˜ê·¼ë¡œì†ì‹¤ì¬í•´ìœ¨â€™ì´ ìˆë‹¤ë©´, â€˜ê·¼ë¡œì†ì‹¤ì¬í•´ìœ¨ (LTIFR)â€™ì²˜ëŸ¼ ì¤‘ë³µë  ìˆ˜ ìˆëŠ” í•­ëª©ë„ ìƒëµí•´.
    - í‘œ í•­ëª©ê³¼ ìœ ì‚¬ì„± íŒë‹¨ ì‹œ ë¬¸ì¥ ì „ì²´ì˜ ì˜ë¯¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•´.
                           
    ğŸ§  ì‘ì„± ë‚´ìš©ì´ ì˜ˆì‹œ í˜•ì‹(ì˜ˆ: 'ì •ì±…, ì ˆì°¨, í™œë™ ë“±')ì´ë¼ í•˜ë”ë¼ë„,
    ê·¸ í•­ëª©ë“¤ì„ ì‹¤ì œ ì…ë ¥ í•„ë“œë¡œ ë°”ê¿”ì„œ êµ¬ì²´ì ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜.

    ì˜ˆë¥¼ ë“¤ì–´, â€˜ë²•ì  ë³´í˜¸ì¢… í˜„í™©â€™ì´ ì‘ì„± ë‚´ìš©ì— ìˆìœ¼ë©´ 
    â†’ ì…ë ¥ í•„ë“œ: â€œë²•ì  ë³´í˜¸ì¢… ì¡´ì¬ ì—¬ë¶€â€, â€œë³´í˜¸ì¢…ëª…â€, â€œì„œì‹ì§€ ìœ„ì¹˜â€ ë“±ìœ¼ë¡œ ì„¸ë¶„í™”í•´ì¤˜.


    ğŸ“‹ ì¶œë ¥ í˜•ì‹ (ì´ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•´! ì•„ë˜ í¬ë§· ì™¸ì˜ ì‘ë‹µì€ ê¸ˆì§€ì•¼.)
    1. í•„ìš”í•œ ë°ì´í„° í•­ëª©ëª… (ë‹¨ìœ„ í¬í•¨ ê¸ˆì§€)
    2. ë‹¨ìœ„ (ê°€ëŠ¥í•˜ë©´ ì¶”ì •)
    3. ì–´ë–¤ ì—°ë„ë³„ ë°ì´í„°ê°€ í•„ìš”í•œì§€ (ì˜ˆ: 2021~2023)
    4. ì„¤ëª… (ì™œ í•„ìš”í•œì§€ ê°„ë‹¨íˆ)
                           
    ì˜ˆ:
    1. **ì´ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰**
    - **ë‹¨ìœ„**: tCO2eq
    - **ì—°ë„ë³„ ë°ì´í„°**: 2021~2023
    - **ì„¤ëª…**: ì¡°ì§ì˜ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œ ì´ëŸ‰ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ í•„ìš”í•¨

    ì§€í‘œë¥¼ ë³´ê³ í•˜ê¸° ìœ„í•´ **ì…ë ¥ í¼ì„ ë§Œë“ ë‹¤ê³  ìƒê°í•˜ê³ **, êµ¬ì²´ì ì´ê³  ëˆ„ë½ ì—†ì´ ì¶”ì²œí•´ì¤˜.
    """)

    # âœ… ê¸°ì¡´ ì²­í¬ + ì‘ì„± ë‚´ìš© ì¶”ì¶œ + í‘œ í…ìŠ¤íŠ¸
    chunk_text = "\n".join(req.chunks)
    table_text = "\n".join(req.table_texts)
    ì‘ì„±_ë¸”ë¡ = extract_ì‘ì„±ë‚´ìš©(req.chunks)

    print("ğŸ“ ì‘ì„± ë‚´ìš© ë¸”ë¡:\n", ì‘ì„±_ë¸”ë¡)

    # âœ… ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„± (ğŸ“ ì‘ì„± ë‚´ìš© ë¸”ë¡ ì¶”ê°€ë¨)
    user = HumanMessage(content=f"""[ì§€í‘œ ID: {req.topic}]

ğŸ“˜ ì§€í‘œ ì„¤ëª… í…ìŠ¤íŠ¸:
{chunk_text}

ğŸ“ ì‘ì„± ë‚´ìš© ìš”ì•½ (ì‘ì„± ë‚´ìš©ì— ë°˜ë“œì‹œ ê¸°ë°˜í•˜ì—¬ ì…ë ¥ í•­ëª©ì„ ì¶”ì²œí•´ì•¼ í•¨):
{ì‘ì„±_ë¸”ë¡}

ğŸ“Š í‘œ ë‚´ìš© (ì°¸ê³ ìš©):
{table_text}
""")

    # âœ… í‘œ í•­ëª©ëª… ì¶”ì¶œ
    table_fieldnames = extract_table_fieldnames(req.table_texts)

    try:
        response = llm.invoke([system, user])
        print("ğŸ“¤ LLM ì‘ë‹µ ì›ë¬¸:\n", response.content)
        parsed_fields = parse_markdown_to_fields(response.content)

        # âœ… ì¤‘ë³µ í•„í„°ë§ ì ìš©
        filtered_fields = [f for f in parsed_fields if "í•­ëª©" in f and not is_redundant(f["í•­ëª©"], table_fieldnames)]
        print("âœ… í•„í„°ë§ í›„ ë‚¨ì€ í•­ëª©:", [f["í•­ëª©"] for f in filtered_fields])

        # âœ… ë¡œê·¸ ì¶”ê°€ (ì´ ì•„ë˜ ì¤„ë“¤)
        print("ğŸ“Œ LLM ì¶”ì²œ í•­ëª©:", [f["í•­ëª©"] for f in parsed_fields])

        table_fieldnames = extract_table_fieldnames(req.table_texts)
        print("ğŸ“‹ ì¶”ì¶œëœ í‘œ í•­ëª©:", table_fieldnames)

        filtered_fields = remove_duplicate_fields(parsed_fields, table_fieldnames)
        print("âœ… í•„í„°ë§ í›„ ë‚¨ì€ í•­ëª©:", [f["í•­ëª©"] for f in filtered_fields])

        return {
            "topic": req.topic,
            "required_data": response.content,
            "required_fields": filtered_fields
        }
    except Exception as e:
        print(f"âŒ infer-required-data ì‹¤íŒ¨: {e}")
        return {
            "topic": req.topic,
            "required_data": "âš ï¸ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "required_fields": []
        }



class DraftRequest(BaseModel):
    topic: str
    inputs: dict
    chunks: List[str]
    table_texts: List[str]
    improvement: Optional[str] = None

@router.post("/generate-draft")
def generate_draft(req: DraftRequest):
    llm = ChatOpenAI(
        model="gpt-4o",
        temperature=0.3,
        max_tokens=1500,
        openai_api_key=key["OPENAI_API_KEY"]
    )

    def format_inputs(inputs: dict) -> str:
        lines = []

        # âœ… ì‚¬ìš©ìê°€ ì‘ì„±í•œ í‘œ HTML ì§ì ‘ ì‚½ì…
        if "filled_table_html" in inputs:
            lines.append("\n\nğŸ“Š ì‚¬ìš©ìê°€ ì‘ì„±í•œ í‘œ:\n")
            lines.append(inputs["filled_table_html"])  # ê·¸ëŒ€ë¡œ ì‚½ì…

        # âœ… ê¸°ì¡´ tableInputs ê¸°ë°˜ í–‰ë ¬ ë°©ì‹ (ì„ íƒ ìœ ì§€ ê°€ëŠ¥)
        if "table" in inputs:
            table_data = inputs["table"]
            rows = {}

            for key, val in table_data.items():
                # key ì˜ˆì‹œ: page1_table0_r2_c3
                m = re.match(r"page\d+_table\d+_r(\d+)_c(\d+)", key)
                if m:
                    r, c = int(m.group(1)), int(m.group(2))
                    rows.setdefault(r, {})[c] = val

            # í–‰ë ¬ ë°©ì‹ìœ¼ë¡œ í‘œ ì¬ì¡°ë¦½ (ì›í•œë‹¤ë©´ ì£¼ì„ì²˜ë¦¬í•´ë„ ë¨)
            lines.append("\n\n<table>")
            for r in sorted(rows):
                lines.append("<tr>")
                for c in sorted(rows[r]):
                    cell_value = rows[r][c].strip()
                    lines.append(f"<td>{cell_value}</td>")
                lines.append("</tr>")
            lines.append("</table>\n")

        # âœ… ë‚˜ë¨¸ì§€ ì¼ë°˜ ì…ë ¥ê°’ ì²˜ë¦¬
        for í•­ëª©, ë‚´ìš© in inputs.items():
            if í•­ëª© in ("table", "filled_table_html"):
                continue
            # âœ… ìƒˆ ì´ë¯¸ì§€ ë°°ì—´ ì²˜ë¦¬
            if í•­ëª© == "ê´€ë ¨ ì´ë¯¸ì§€" and isinstance(ë‚´ìš©, list):
                for item in ë‚´ìš©:
                    url = item.get("url")
                    title = item.get("title", "")
                    description = item.get("description", "")
                    if url:
                        lines.append(f"\n\n![{title}]({url})\n**{title}**\n{description}")
                continue

            # ê¸°ì¡´ dict ì²˜ë¦¬
            if isinstance(ë‚´ìš©, dict):
                if "url" in ë‚´ìš©:
                    lines.append(f"- {í•­ëª©}: ![ì´ë¯¸ì§€]({ë‚´ìš©['url']})")
                else:
                    for ì—°ë„, ê°’ in ë‚´ìš©.items():
                        if isinstance(val := ê°’, dict) and "url" in val:
                            lines.append(f"- {ì—°ë„}ë…„ {í•­ëª©}: ![ì´ë¯¸ì§€]({val['url']})")
                        else:
                            lines.append(f"- {ì—°ë„}ë…„ {í•­ëª©}: {ê°’}")
            elif isinstance(ë‚´ìš©, str):
                lines.append(f"- {í•­ëª©}: {ë‚´ìš©}")

        return "\n".join(lines)




    formatted_inputs = format_inputs(req.inputs)

    system = SystemMessage(content="""
    ë„ˆëŠ” ESG ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì•¼.

    ì‚¬ìš©ìê°€ ì œê³µí•œ ì§€í‘œ ì„¤ëª… í…ìŠ¤íŠ¸ì™€ í‘œ ë‚´ìš©ì€ ë³´ê³ ì„œ ì‘ì„± ê°€ì´ë“œì—ì„œ ë°œì·Œí•œ ê²ƒì´ë©°,
    ë„ˆëŠ” ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ì§€í‘œì˜ ë³´ê³ ì„œ ì´ˆì•ˆì„ ì‘ì„±í•´ì•¼ í•´.

    â–¶ ì „ë°˜ í†¤&ìŠ¤íƒ€ì¼
    - ê³µì‹ì Â·ê°ê´€ì  ë¬¸ì²´: 3ì¸ì¹­, ì •ì¤‘í•œ í˜„ì¬Â·ê³¼ê±° ì‹œì œ ì‚¬ìš© (ì˜ˆ: â€œê°ì†Œí•˜ì˜€ìŠµë‹ˆë‹¤â€, â€œì¦ê°€í•˜ì˜€ìŠµë‹ˆë‹¤â€)
    - ê²½ì˜ì§„ ëŒ€ìƒ ë¹„ì¦ˆë‹ˆìŠ¤ ë ˆí¬íŠ¸ ì–´ì¡°
    - GRI, TCFD, SASB ë“± êµ­ì œÂ·êµ­ë‚´ í”„ë ˆì„ì›Œí¬ ì–¸ê¸‰ ê°€ëŠ¥
    - ì‚¬ì‹¤Â·ìˆ˜ì¹˜ ì¤‘ì‹¬
    - ë¬¸ì¥ ì—°ê²° í—ˆìš©: â€œâ€¦í•˜ê³ , ì´ì— ë”°ë¼â€¦â€, â€œâ€¦í•˜ë©°â€¦â€ ë“± ë³µë¬¸ í˜•íƒœë¡œ ì‚¬ì‹¤ì„ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²° ê°€ëŠ¥
    - ë¶€ì‚¬Â·ì ‘ì†ì‚¬ í™œìš© ì¥ë ¤: â€œíŠ¹íˆâ€, â€œí•œí¸â€, â€œë˜í•œâ€ ë“± ê°•ì¡° ë¶€ì‚¬ ë° ì ‘ì†ì‚¬ ì‚¬ìš©ì„ í—ˆìš©í•´ ë¦¬ë“¬ê° ë¶€ì—¬
    - ë³µë¬¸ ì¼ë¶€ í—ˆìš©: ë‘ ê°œ ì´ìƒì˜ ì‚¬ì‹¤ì„ í•˜ë‚˜ì˜ ë¬¸ì¥ì—ì„œ ì—°ê²°í•  ìˆ˜ ìˆë„ë¡ í—ˆìš©
    - ê²©ì‹ì²´ ì¢…ê²°ì–´ë¯¸ ì‚¬ìš©: ëª¨ë“  ë¬¸ì¥ì€ â€œê°ì†Œí•˜ì˜€ìŠµë‹ˆë‹¤â€, â€œí™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤â€, â€œì¶”ì§„í•˜ê³  ìˆìŠµë‹ˆë‹¤â€ ë“±ì˜ ì •ì¤‘í•œ ì–´ë¯¸ë¡œ ëë§ºê¸°

    â–¶ ê¸ˆì§€ì‚¬í•­
    - ì¶”ì¸¡ì„± ë¬¸ì¥(â€œ~ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤â€, â€œ~ë¡œ í•´ì„ë©ë‹ˆë‹¤â€) ì‚¬ìš© ê¸ˆì§€
    - ì ˆëŒ€ ì¶”ì¸¡, ì›ì¸ í•´ì„(â€œìƒì‚° í™œë™ì´ í™œë°œí•´ì§„ ê²°ê³¼â€) ì‚¬ìš© ê¸ˆì§€
    - ë°ì´í„° ë¯¸ì œê³µ í•­ëª©ì— ëŒ€í•œ ì´ìœ  ì¶”ì¸¡ ê¸ˆì§€
    - ë©”íƒ€ í‘œí˜„ ê¸ˆì§€ (ì˜ˆ: â€œì´ í‘œëŠ” íšŒì‚¬ì˜ ë…¸ë ¥ì„ ë³´ì—¬ì¤€ë‹¤â€ ë“±)

    ì´ˆì•ˆì„ ì‘ì„±í•  ë•Œ ë‹¤ìŒ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ë”°ë¼ì•¼ í•´:

    1. ì„¹ì…˜ ì œëª©
    - ì˜ˆ: â€œìƒë¬¼ë‹¤ì–‘ì„± ë³´í˜¸ ì •ì±…â€, â€œë²•ì  ë³´í˜¸ì¢… ê´€ë¦¬â€

    2. í•µì‹¬ í…Œë§ˆ ì†Œì œëª© êµ¬ì„±
    - ì…ë ¥ê°’ í•­ëª©ì´ ë§ì„ ê²½ìš° ì†Œì œëª©ì€ 2ê°œ ì´ìƒìœ¼ë¡œ ììœ ë¡­ê²Œ ë‚˜ëˆ„ê³ , ì˜ë¯¸ìƒ ìœ ì‚¬í•œ í•­ëª©ì€ ë¬¶ì–´ì„œ ì„¤ëª…í•´.
    - ì˜ˆ: "ë³´í˜¸ ì •ì±… ë° ì˜í–¥ ì¸¡ì •", "ë²•ì  ë³´í˜¸ì¢… ê´€ë¦¬", "ì§€ì—­ì‚¬íšŒ ì˜ê²¬ ìˆ˜ë ´"

    3. ì†Œì œëª©ë³„ ë¬¸ë‹¨ êµ¬ì„±
    - ì†Œì œëª© ì•„ë˜ì— ê´€ë ¨ ì…ë ¥ê°’ì„ ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•´. í•­ëª©ëª…ì„ ê·¸ëŒ€ë¡œ ë‚˜ì—´í•˜ì§€ ë§ê³  ì¬êµ¬ì„±í•´ì„œ í‘œí˜„í•´.
    - ì˜ˆ: â€œë²•ì  ë³´í˜¸ì¢… ì¡´ì¬ ì—¬ë¶€: ì˜ˆâ€ â†’ â€œë²•ì  ë³´í˜¸ì¢…ì´ ì¡´ì¬í•˜ì—¬ ê´€ë ¨ ë³´í˜¸ ì¡°ì¹˜ë¥¼ ì‹œí–‰í•˜ì˜€ìŠµë‹ˆë‹¤.â€
    - ë‹¨ë‹µí˜• ì…ë ¥ê°’(ì˜ˆ/ì•„ë‹ˆì˜¤, í…ìŠ¤íŠ¸)ë„ ë§ˆì¹˜ ë³´ê³ ì„œ ë¬¸ì¥ì²˜ëŸ¼ ì—°ê²°í•˜ì—¬ ì‘ì„±í•´.
    - í•­ëª©ì„ ë‚˜ì—´í•˜ì§€ ë§ê³ , ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ëœ íë¦„ì˜ ì„œìˆ í˜• ë¬¸ë‹¨ì„ êµ¬ì„±í•´.

    4. í‘œ
    - ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‘œê°€ ì¡´ì¬í•˜ë©´, HTML í˜•ì‹ìœ¼ë¡œ ë³¸ë¬¸ì— ê·¸ëŒ€ë¡œ ì‚½ì…í•´.
    - ì˜ˆ: `ğŸ“Š ì•„ë˜ í‘œëŠ” ___ì˜ ì‚¬ìš© í˜„í™©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.` ê°™ì€ ë¬¸ì¥ìœ¼ë¡œ ì‹œì‘í•œ í›„, `<table>...</table>` ì‚½ì…

    5. ì´ë¯¸ì§€
    - ì…ë ¥ê°’ì— ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ê²½ìš°, ë°˜ë“œì‹œ `![ì„¤ëª…](URL)` ë§ˆí¬ë‹¤ìš´ ì´ë¯¸ì§€ í˜•ì‹ìœ¼ë¡œ ì‚½ì…í•´.
    - íŠ¹íˆ, `ê´€ë ¨ ì´ë¯¸ì§€` í•­ëª©ì´ ë°°ì—´ì¸ ê²½ìš°, ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´:
    - ![ì œëª©](ì´ë¯¸ì§€ ë§í¬)
    - ì œëª©ì€ êµµê²Œ (`**ì œëª©**`)
    - ì„¤ëª…ì€ ì œëª© ì•„ë˜ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±
    - ì ˆëŒ€ `[í…ìŠ¤íŠ¸](URL)`ì²˜ëŸ¼ ë§í¬ë§Œ ì“°ì§€ ë§ê³ , ì‹¤ì œ ì´ë¯¸ì§€ê°€ í‘œì‹œë˜ë„ë¡ ì¶œë ¥í•  ê²ƒ.

    6. ë§ˆì§€ë§‰ ë‹¨ë½ êµ¬ì„±
    - ì‚¬ìš©ìê°€ ì…ë ¥í•œ â€˜ê°œì„  ë…¸ë ¥ ë° í™œë™â€™ ë‚´ìš©ì´ ìˆì„ ê²½ìš° ë§ˆì§€ë§‰ ë‹¨ë½ì— ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ê³ , ì†Œì œëª©ì€ ììœ ë¡­ê²Œ ì„¤ì •.
    - ì˜ˆ: â€œë˜í•œ, ___ í™œë™ì„ í†µí•´ ___ ê´€ë¦¬ ê°•í™”ë¥¼ ìœ„í•œ ë…¸ë ¥ì„ ì§€ì†í•˜ê³  ìˆìŠµë‹ˆë‹¤.â€

    ğŸ“ ì¶œë ¥ í˜•ì‹
    - 2~3ë¬¸ë‹¨ ì´ìƒì˜ ì„œìˆ í˜•ìœ¼ë¡œ ì‘ì„±
    - ì˜ë¯¸ë³„ ì†Œì œëª©ìœ¼ë¡œ êµ¬ë¶„
    - í•„ìš” ì‹œ ì‚¬ìš©ì ë°ì´í„° ê¸°ë°˜ í‘œë¥¼ í•˜ë‚˜ í¬í•¨
                           
    ğŸ“Œ ì¶”ê°€ ì§€ì¹¨ (ì •í™•ì„±Â·ë¬¸ì¥í™” ê°•í™”)
    - ì‚¬ìš©ìê°€ ì…ë ¥í•˜ì§€ ì•Šì€ í•­ëª©ì„ ì„ì˜ë¡œ ìƒì„±í•˜ê±°ë‚˜ í™•ì¥í•˜ì§€ ë§ˆ. (ì˜ˆ: â€œêµ­ì œ í˜‘ì•½ì˜ í¬ê´„ì„± ì—¬ë¶€â€ ë“±)
    - 'ì˜ˆ/ì•„ë‹ˆì˜¤'ë¡œ ëë‚˜ëŠ” ë‹¨ë‹µí˜• í‘œí˜„ì€ ì§€ì–‘í•˜ê³ , ê·¸ ì˜ë¯¸ë¥¼ ì •ì±…Â·í™œë™Â·ì¡°ì¹˜ ë“±ê³¼ ì—°ê²°ëœ ì„œìˆ í˜• ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„í•´.
    - ì˜ˆ: â€œë²•ì  ë³´í˜¸ì¢… ì¡´ì¬ ì—¬ë¶€: ì˜ˆâ€ â†’ â€œë²•ì  ë³´í˜¸ì¢…ì´ í™•ì¸ë˜ì–´, ì´ì— ë”°ë¥¸ ë³´í˜¸ ì¡°ì¹˜ë¥¼ ìˆ˜ë¦½í•˜ì˜€ìŠµë‹ˆë‹¤.â€ì²˜ëŸ¼ ë°”ê¿” ì¨.
    - â€œì¡´ì¬í•˜ì§€ ì•Šì•˜ë‹¤â€, â€œì ìš©ë˜ì§€ ì•Šì•˜ë‹¤â€ ë“±ì˜ í‘œí˜„ë„ ê°€ëŠ¥í•˜ë©´ ì™„ê³¡í•˜ê²Œ í‘œí˜„í•˜ê³ , ë¶ˆí•„ìš”í•œ ë¶€ì • í‘œí˜„ì€ í”¼í•  ê²ƒ.

                           
    â–¶ ìˆ˜ì¹˜ ë° í‘œ ì‘ì„± ê·œì¹™

    - í‘œì— í¬í•¨ëœ ìˆ˜ì¹˜ëŠ” ë³¸ë¬¸ì— ë‹¤ì‹œ ì„œìˆ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    - ë³¸ë¬¸ì€ êµ¬ì²´ì  ìˆ˜ì¹˜ë³´ë‹¤ëŠ” **ë³€í™” ê²½í–¥(ì˜ˆ: ì¦ê°€, ê°ì†Œ, ìœ ì§€)** ê³¼ **ì˜ë¯¸ ìš”ì•½** ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
    - ì˜ˆì‹œ ë¬¸ì¥: â€œìµœê·¼ 3ë…„ê°„ ì›ë¶€ìì¬ ì‚¬ìš©ëŸ‰ì´ ì¦ê°€ ì¶”ì„¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤â€, â€œì‚¬ìš© íš¨ìœ¨ì´ ê°œì„ ë˜ë©° ì§‘ì•½ë„ê°€ ì™„í™”ë˜ì—ˆìŠµë‹ˆë‹¤â€ ë“±.
    - ìˆ˜ì¹˜ì˜ ë¹„êµ ë° êµ¬ì²´ì ì¸ ë³€í™”ëŸ‰ì€ **ë³¸ë¬¸ì´ ì•„ë‹Œ í‘œë¥¼ í†µí•´ ì‹œê°ì ìœ¼ë¡œ ì „ë‹¬**í•©ë‹ˆë‹¤.
    - ì´ë¥¼ í†µí•´ ë³¸ë¬¸ì€ ìˆ˜ì¹˜ê°€ ì•„ë‹Œ ì •ì±…, ëŒ€ì‘ ì „ëµ, í™œë™ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
                           
    """)



    joined_chunks = "\n".join(req.chunks)
    joined_tables = "\n".join(req.table_texts)

    user = HumanMessage(content=f"""
    [ì§€í‘œ ID: {req.topic}]

    ğŸ“˜ ì§€í‘œ ì„¤ëª… í…ìŠ¤íŠ¸:
    {joined_chunks}

    ğŸ“Š ì‘ì„± ê°€ì´ë“œ í‘œ:
    {joined_tables}

    ğŸ“¥ ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°:
    {formatted_inputs}

    ğŸ“ˆ ê°œì„  ë…¸ë ¥ ë° í™œë™:
    {req.improvement or 'ì—†ìŒ'}
    """)

    try:
        response = llm.invoke([system, user])
        return {
            "draft": response.content.strip()
        }
    except Exception as e:
        print("âŒ ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨:", e)
        return {
            "draft": "âš ï¸ ì´ˆì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }



@router.post("/summarize-indicator")
def summarize_indicator(req: InferDataRequest):
    llm = ChatOpenAI(model="gpt-4o", temperature=0.3)

    system = SystemMessage(content="""
ë„ˆëŠ” ESG ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì•¼.

ì•„ë˜ ì§€í‘œ ì„¤ëª… í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ìš”ì•½í•´ì¤˜:

- ì´ ì§€í‘œì˜ ëª©ì ê³¼ ì˜ë¯¸ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ê³ , *ì¤„ì„ ë°”ê¾¼ í›„ì—* ì‘ì„± ë°©ë²•ì´ë‚˜ ë³´ê³  ì‹œ ìœ ì˜í•  ì ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜
- í™”ë ¤í•œ ë¬¸êµ¬ ì—†ì´ ëª…í™•í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì¨ì¤˜
- ë°˜ë“œì‹œ ì§€í‘œ ì„¤ëª… í…ìŠ¤íŠ¸ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, ì§€ì–´ë‚´ì§€ ë§ê³  ì¨ì¤˜

    """)

    chunks = "\n".join(req.chunks)
    user = HumanMessage(content=f"[ì§€í‘œ ID: {req.topic}]\n\n{chunks}")

    try:
        res = llm.invoke([system, user])
        return {"summary": res.content.strip()}
    except Exception as e:
        print("âŒ ìš”ì•½ ì‹¤íŒ¨:", e)
        return {"summary": "ìš”ì•½ ì‹¤íŒ¨"}
    

# â¬‡ï¸ ì´ˆì•ˆ ì €ì¥ API
@router.post("/save-draft")
async def save_draft_api(req: Request):  # âœ… async def
    data = await req.json()              # âœ… await ì¶”ê°€
    topic = data.get("topic")
    company = data.get("company")
    draft = data.get("draft")
    save_draft(topic, company, draft)
    return {"message": "âœ… Draft saved"}

@router.get("/indicator-status", response_model=Dict[str, str])
def get_indicator_status():
    raw = list(draft_collection.find(
        {}, {"_id": 0, "topic": 1, "status": 1, "draft": 1}
    ))
    result = {}

    for doc in raw:
        code = doc["topic"]
        if doc.get("status") == "completed":
            result[code] = "completed"
        elif doc.get("status") == "saved":
            result[code] = "saved"
        elif doc.get("draft"):
            result[code] = "saved"
        else:
            # âœ… ì¶”ê°€: draft_inputs í™•ì¸
            input_doc = input_collection.find_one({"topic": code})
            if input_doc and (
                input_doc.get("inputs") or input_doc.get("table") or input_doc.get("improvement")
            ):
                result[code] = "saved"  # âœ… ì…ë ¥ê°’ë§Œ ìˆì–´ë„ ì €ì¥ë¨ ì²˜ë¦¬
            else:
                result[code] = "empty"

    return result


@router.post("/complete-indicator/{code}")
def complete_indicator(code: str):
    try:
        result = draft_collection.update_one(
            {"topic": code},
            {"$set": {"status": "completed"}},
            upsert=True
        )
        if not result.acknowledged:
            raise RuntimeError("ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨")
        return {"success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# â¬‡ï¸ ì´ˆì•ˆ ë¶ˆëŸ¬ì˜¤ê¸° API
@router.get("/load-draft")
def load_draft_api(topic: str, company: str):
    draft = load_draft(topic, company)
    return {"draft": draft or ""}


@router.delete("/delete-draft")
async def delete_draft_api(req: DeleteDraftRequest):
    # services/draft_store.py ì— delete í•¨ìˆ˜ê°€ ì—†ìœ¼ë©´ ë°”ë¡œ pymongo ì½”ë“œë¡œ êµ¬í˜„
    from services.draft_store import delete_draft  # í˜¹ì€ ì§ì ‘ MongoDB delete ë¡œì§
    deleted = delete_draft(req.topic, req.company)
    if not deleted:
        raise HTTPException(status_code=404, detail="Draft not found")
    return {"deleted": True}